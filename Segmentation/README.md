# Segmentation Methods in VisionScores

The segmentation techniques used to extract system-level images from full-page piano scores in the VisionScores dataset are detailed in the full paper; a summary is provided below. The methods range from a classical threshold-based approach to neural-network-based architectures, including a custom-designed post-processing network. These methods were designed to satisfy the structural constraints required for the dataset: format uniformity and preservation of the semantic integrity of two-handed piano systems.


## 1. Threshold-Based Segmentation

The classical segmentation approach is grounded in the observation that musical systems, particularly in two-handed piano scores, consist of horizontally aligned and graphically dense regions. These dense regions, representing staves, are typically separated by white space and exhibit consistent vertical structure.

### Preprocessing

Given a grayscale image $I \in \mathbb{R}^{H \times W}$, where $H$ and $W$ are the height and width respectively, a series of preprocessing steps are applied:

1. **Image inversion**:

   $$I' = 255 - I$$

   to highlight darker staff lines and symbols.

2. **Gaussian filtering**:

   $$I'' = G_\sigma * I'$$

   where $G_\sigma$ is a 2D Gaussian kernel, and $*$ denotes convolution. This step reduces high-frequency noise introduced by isolated musical symbols.

3. **Row-wise summation**:  
   A 1D profile $p \in \mathbb{R}^H$ is computed as  

   $$p(i) = \sum_{j=1}^{W} I''(i, j)$$  

   for all $i \in [1, H]$. Local minima in this profile correspond to low-density (white space) regions between systems.

### System Boundary Detection

The profile $p$ is scanned for critical points—local minima and maxima. To distinguish true inter-system gaps from intra-system separations (e.g., between right and left-hand staves), a dynamic threshold is applied:

- Let $\mu_{\text{min}}$ be the mean of the local minima values.
- A value $m$ is considered a true separator if

  $$m < \alpha \cdot \mu_{\text{min}}$$

  where $\alpha \in (0,1)$ is a tunable parameter, empirically set to $\alpha = 0.8$.

To resolve over-segmentation caused by noisy minima, nearby minima are grouped, and the lowest point in each group is retained. Analogous logic is applied to maxima when grouping boundaries.

This method was used for constructing the segmented systems in the **Franz Liszt scenario**.


## 2. U-Net Segmentation

The U-Net architecture is used to produce segmentation masks that highlight the locations of musical systems in the score image. However, due to the absence of labeled segmentation maps in the source data, a synthetic segmentation dataset was constructed for supervised training.

### Synthetic Dataset Construction

Artificial score sheets were generated by randomly selecting system-level images from the Franz Liszt scenario and stacking them vertically to form synthetic full pages. Corresponding binary segmentation maps were created by assigning each system a value of 1 in its vertical span, and 0 elsewhere. A sample image and its associated segmentation map are shown below:

![vision_scores_logo](./docs/synthetic_scoreMask.png)

### Network Architecture and Training

The U-Net used here is a reduced version with three downsampling and upsampling stages:

- Encoder channels: 8 → 16 → 32
- Decoder mirrors the encoder
- Final activation: Sigmoid

Let $x \in \mathbb{R}^{H \times W}$ be the input image and $f(x)$ the U-Net output with values in $[0, 1]$. The output is expected to approximate a binary segmentation map.

### Profile-Based Postprocessing

To use the network output analogously to the threshold-based method:

1. **Row-wise sum**:

   $$p_{\text{net}}(i) = \sum_{j=1}^{W} f(x)_{i, j}$$

2. **Minima detection**:
   Thresholding is again applied to detect system boundaries.

A major limitation arises when applying the sigmoid function: the network output becomes overly smoothed, diminishing the contrast between system and non-system regions in $ p_{\text{net}} $, leading to segmentation failures.


## 3. CutNet Segmentation

To resolve the limitations observed with sigmoid flattening in U-Net output, an adaptive transformation module—**CutNet**—was developed to restore a usable segmentation profile.

### Architecture Overview

CutNet consists of two stages:

1. **Adaptive Subtraction Layer**:

   $$y(x) = \sigma \left(x - \text{ReLU}\left( \sum_h x^\top W_1 + b_1 \right) \right)$$

   This learns to subtract a spatially adaptive threshold from the U-Net output $x$, where $W_1$ and $b_1$ are learned weights and biases.

2. **Profile Transformation Module**:

   $$z(y) = \sigma\left(U_{1:3} \circledcirc V_5 \ast \left[ \tanh \left( V_{1:4} \ast \sum_h y^\top \right) W_2 + b_2 \right]\right)$$

   This second stage maps the transformed profile into a refined 1D representation that emulates the ideal segmentation profile—essentially a step function indicating system boundaries.

Here:
- $x$ represent U-Net output,
- $\sum_h$ denotes the sum per row of two-dimensional input,
- $\sigma$ is sigmoid activation function,
- $W_1, W_2, b_1, b_2$ are the wights of the linear layers and their respective biases,
- $\circledast, V_{1:4}$ represent convolution and its weights,
- $\circledcirc, U_{1:3}$ denotes transposed convolution and its weights.



## Metrics

To evaluate segmentation quality, standard metrics were computed over a synthetic validation dataset. The following table presents the Intersection over Union (*IoU*), *F1-score*, *Precision*, and *Recall* for the two learning-based segmentation models:

| Model  | IoU   | F1    | Precision | Recall |
|--------|-------|-------|-----------|--------|
| U-Net  | 0.584 | 0.672 | 0.729     | 0.787  |
| CutNet | 0.485 | 0.604 | 0.744     | 0.612  |

While U-Net achieved the highest segmentation metrics in isolation, CutNet demonstrated greater practical effectiveness in producing structurally complete and consistent system crops suitable for dataset construction.
